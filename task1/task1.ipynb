{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b67fba-2eae-4a79-8063-44314e68629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "precision, recall, f1,y_true,y_pred = calculate_metrics(summary, reference_summary)\n",
    "print(\"\\nPrecision: {:.4f}\".format(precision))\n",
    "print(\"Recall: {:.4f}\".format(recall))\n",
    "print(\"F1 Score: {:.4f}\".format(f1))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fc83fa-570d-4b7c-8888-f38340bd669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"saved_model/\"\n",
    "try:\n",
    "    model = SentenceTransformer(MODEL_PATH)\n",
    "    print(\"Loaded model from saved path.\")\n",
    "except:\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"Downloaded and saved model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ee3e8-4c66-4825-a25d-0848fa93c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee94f9-7535-44a4-a2a0-4d66868edeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_sentences(text, processed_sentences, original_sentences):\n",
    "    sentence_scores = {}\n",
    "    text_embedding = model.encode(text, convert_to_tensor=True)\n",
    "\n",
    "    for i, sentence in enumerate(processed_sentences):\n",
    "        sentence_embedding = model.encode(sentence, convert_to_tensor=True)\n",
    "        similarity = util.pytorch_cos_sim(sentence_embedding, text_embedding).item()\n",
    "        sentence_scores[original_sentences[i]] = similarity\n",
    "\n",
    "    ranked_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
    "    return ranked_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bfdb2-27ac-4d0a-9a09-5b79888cade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_sentences(text, top_k=3, ensure_diversity=True, diversity_threshold=0.5):\n",
    "    original_sentences = sent_tokenize(text)\n",
    "    processed_sentences = [preprocess_text(sentence) for sentence in original_sentences]\n",
    "\n",
    "    if top_k > len(processed_sentences):\n",
    "        top_k = len(processed_sentences)\n",
    "\n",
    "    ranked_sentences = rank_sentences(text, processed_sentences, original_sentences)\n",
    "\n",
    "    if ensure_diversity:\n",
    "        selected_sentences = []\n",
    "        embeddings = [model.encode(sent, convert_to_tensor=True) for sent in ranked_sentences]\n",
    "\n",
    "        for i, sent in enumerate(ranked_sentences):\n",
    "            if len(selected_sentences) == 0:\n",
    "                selected_sentences.append(sent)\n",
    "            else:\n",
    "                is_diverse = True\n",
    "                current_embedding = embeddings[i]\n",
    "\n",
    "                for selected_sent in selected_sentences:\n",
    "                    selected_embedding = model.encode(selected_sent, convert_to_tensor=True)\n",
    "                    similarity = util.pytorch_cos_sim(current_embedding, selected_embedding).item()\n",
    "                    if similarity > diversity_threshold:\n",
    "                        is_diverse = False\n",
    "                        break\n",
    "\n",
    "                if is_diverse:\n",
    "                    selected_sentences.append(sent)\n",
    "\n",
    "            if len(selected_sentences) == top_k:\n",
    "                break\n",
    "        return selected_sentences\n",
    "    else:\n",
    "        return ranked_sentences[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d2070-3074-4544-8ab7-cb13ddd78f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text, summary_length=5, ensure_diversity=True, diversity_threshold=0.7):\n",
    "    if not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    summary_sentences = retrieve_top_sentences(text, top_k=summary_length,\n",
    "                                               ensure_diversity=ensure_diversity,\n",
    "                                               diversity_threshold=diversity_threshold)\n",
    "    \n",
    "    original_sentences = sent_tokenize(text)\n",
    "    ordered_summary = [sent for sent in original_sentences if sent in summary_sentences]\n",
    "    \n",
    "    return ' '.join(ordered_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ffcb2-2d26-4a38-850a-9426bf52c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(generated_summary, reference_summary, model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
    "    model = SentenceTransformer(model_name)  \n",
    "    \n",
    "    generated_embedding = model.encode(generated_summary, convert_to_tensor=True)\n",
    "    reference_embedding = model.encode(reference_summary, convert_to_tensor=True)\n",
    "    \n",
    "    similarity = util.pytorch_cos_sim(generated_embedding, reference_embedding).item()\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50987660-d441-49d3-b7e0-6da858e1436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(generated_summary, reference_summary):\n",
    "    true_positives = sum(1 for word in generated_summary if word in reference_summary)\n",
    "    false_positives = sum(1 for word in generated_summary if word not in reference_summary)\n",
    "    false_negatives = sum(1 for word in reference_summary if word not in generated_summary)\n",
    "    \n",
    "    total_samples = true_positives + false_positives + false_negatives\n",
    "    \n",
    "    y_true = [1] * true_positives + [0] * (total_samples - true_positives)\n",
    "    y_pred = [1] * true_positives + [1] * false_positives + [0] * false_negatives\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    return precision, recall, f1 ,y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfac396-cecd-46de-91c6-2ef62ed32018",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term \"artificial intelligence\" is often used to describe machines that mimic cognitive functions that humans associate with the human mind, such as learning and problem-solving. As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says \"AI is whatever hasn't been done yet.\" For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n",
    "\"\"\"\n",
    "\n",
    "reference_summary = \"AI demonstrates intelligence by machines, contrasting human intelligence. It is defined as the study of intelligent agents that maximize their chances of achieving goals. The term is often used to describe machines mimicking cognitive functions like learning and problem-solving. As machines improve, tasks requiring intelligence are often redefined, known as the AI effect. Optical character recognition is an example of a technology that has become routine and is no longer considered AI.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a18039-7079-4dbf-9989-43e459749c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_length = 3\n",
    "summary = generate_summary(text, summary_length=summary_length, ensure_diversity=True, diversity_threshold=0.5)\n",
    "print(\"\\nGenerated Summary:\\n\", summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
