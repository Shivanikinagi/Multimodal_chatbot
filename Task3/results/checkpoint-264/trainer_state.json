{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 264,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11363636363636363,
      "grad_norm": 1.0362143516540527,
      "learning_rate": 1.9242424242424244e-05,
      "loss": 0.6898,
      "step": 10
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 1.3279118537902832,
      "learning_rate": 1.8484848484848487e-05,
      "loss": 0.6661,
      "step": 20
    },
    {
      "epoch": 0.3409090909090909,
      "grad_norm": 3.516667127609253,
      "learning_rate": 1.772727272727273e-05,
      "loss": 0.6458,
      "step": 30
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 2.3904237747192383,
      "learning_rate": 1.6969696969696972e-05,
      "loss": 0.6121,
      "step": 40
    },
    {
      "epoch": 0.5681818181818182,
      "grad_norm": 4.923677444458008,
      "learning_rate": 1.6212121212121212e-05,
      "loss": 0.5575,
      "step": 50
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 4.013904094696045,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.5222,
      "step": 60
    },
    {
      "epoch": 0.7954545454545454,
      "grad_norm": 4.973859786987305,
      "learning_rate": 1.4696969696969699e-05,
      "loss": 0.5604,
      "step": 70
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 4.927737712860107,
      "learning_rate": 1.3939393939393942e-05,
      "loss": 0.5284,
      "step": 80
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.45539265871047974,
      "eval_runtime": 36.5045,
      "eval_samples_per_second": 16.464,
      "eval_steps_per_second": 1.041,
      "step": 88
    },
    {
      "epoch": 1.0227272727272727,
      "grad_norm": 4.7607316970825195,
      "learning_rate": 1.3181818181818183e-05,
      "loss": 0.4795,
      "step": 90
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 4.865307807922363,
      "learning_rate": 1.2424242424242425e-05,
      "loss": 0.4445,
      "step": 100
    },
    {
      "epoch": 1.25,
      "grad_norm": 3.127270221710205,
      "learning_rate": 1.1666666666666668e-05,
      "loss": 0.3808,
      "step": 110
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 3.8095884323120117,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.4323,
      "step": 120
    },
    {
      "epoch": 1.4772727272727273,
      "grad_norm": 3.9864554405212402,
      "learning_rate": 1.0151515151515152e-05,
      "loss": 0.3639,
      "step": 130
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 5.151229381561279,
      "learning_rate": 9.393939393939396e-06,
      "loss": 0.3473,
      "step": 140
    },
    {
      "epoch": 1.7045454545454546,
      "grad_norm": 6.766392230987549,
      "learning_rate": 8.636363636363637e-06,
      "loss": 0.3101,
      "step": 150
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 6.999125003814697,
      "learning_rate": 7.87878787878788e-06,
      "loss": 0.3747,
      "step": 160
    },
    {
      "epoch": 1.9318181818181817,
      "grad_norm": 5.062282085418701,
      "learning_rate": 7.121212121212122e-06,
      "loss": 0.3814,
      "step": 170
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.4382392168045044,
      "eval_runtime": 40.1409,
      "eval_samples_per_second": 14.972,
      "eval_steps_per_second": 0.947,
      "step": 176
    },
    {
      "epoch": 2.0454545454545454,
      "grad_norm": 5.561882019042969,
      "learning_rate": 6.363636363636364e-06,
      "loss": 0.3321,
      "step": 180
    },
    {
      "epoch": 2.159090909090909,
      "grad_norm": 2.2487950325012207,
      "learning_rate": 5.606060606060606e-06,
      "loss": 0.2449,
      "step": 190
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 3.8875908851623535,
      "learning_rate": 4.848484848484849e-06,
      "loss": 0.2531,
      "step": 200
    },
    {
      "epoch": 2.3863636363636362,
      "grad_norm": 11.382914543151855,
      "learning_rate": 4.0909090909090915e-06,
      "loss": 0.2629,
      "step": 210
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.5820696353912354,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.3925,
      "step": 220
    },
    {
      "epoch": 2.6136363636363638,
      "grad_norm": 7.837915897369385,
      "learning_rate": 2.575757575757576e-06,
      "loss": 0.3193,
      "step": 230
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 3.131657361984253,
      "learning_rate": 1.8181818181818183e-06,
      "loss": 0.2132,
      "step": 240
    },
    {
      "epoch": 2.840909090909091,
      "grad_norm": 2.4891815185546875,
      "learning_rate": 1.0606060606060608e-06,
      "loss": 0.2835,
      "step": 250
    },
    {
      "epoch": 2.9545454545454546,
      "grad_norm": 5.191104412078857,
      "learning_rate": 3.0303030303030305e-07,
      "loss": 0.2654,
      "step": 260
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.4570637345314026,
      "eval_runtime": 38.5416,
      "eval_samples_per_second": 15.594,
      "eval_steps_per_second": 0.986,
      "step": 264
    }
  ],
  "logging_steps": 10,
  "max_steps": 264,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 139090768588800.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
