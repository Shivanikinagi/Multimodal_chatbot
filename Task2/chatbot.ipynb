{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de55ba-9da9-4ddb-8aa8-3729d4a9baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Use a smaller text model for CPU\n",
    "text_generator = pipeline(\"text-generation\", model=\"distilgpt2\", max_length=200)\n",
    "\n",
    "# Set device to CPU explicitly\n",
    "device = \"cpu\"\n",
    "\n",
    "# Load a CPU-friendly image generation model\n",
    "image_generator = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\n",
    "\n",
    "def generate_image(prompt):\n",
    "    try:\n",
    "        print(\"Generating image, please wait...\")\n",
    "        image = image_generator(prompt).images[0]\n",
    "        image_path = \"generated_image.png\"\n",
    "        image.save(image_path)\n",
    "        return f\"Chatbot: Image saved as {image_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error generating image: {e}\"\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(prompt):\n",
    "    try:\n",
    "        response = text_generator(prompt, max_length=200, num_return_sequences=1)\n",
    "        return response[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        return f\"Error generating text: {e}\"\n",
    "\n",
    "# Multi-modal chatbot\n",
    "def multimodal_chatbot():\n",
    "    print(\"Welcome to the Multi-Modal Chatbot! Type 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Image generation\n",
    "        if \"generate image\" in user_input.lower():\n",
    "            prompt = user_input.replace(\"generate image\", \"\").strip()\n",
    "            if prompt:\n",
    "                print(\"Chatbot: Generating an image, please wait...\")\n",
    "                image_path = generate_image(prompt)\n",
    "                print(f\"Chatbot: Here's your image saved as {image_path}\" if \"Error\" not in image_path else image_path)\n",
    "            else:\n",
    "                print(\"Chatbot: Please provide a description for the image.\")\n",
    "\n",
    "        # General text processing\n",
    "        else:\n",
    "            print(\"Chatbot: Processing your query...\")\n",
    "            response = generate_text(user_input)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    multimodal_chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3c3032-9e76-4aa1-a13b-9c941cea25de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07f02b-4387-4934-8e59-31408c8b77f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
