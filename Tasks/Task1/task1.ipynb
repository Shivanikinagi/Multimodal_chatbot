{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b67fba-2eae-4a79-8063-44314e68629a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shivani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shivani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shivani\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60fc83fa-570d-4b7c-8888-f38340bd669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from saved path.\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"saved_model/\"\n",
    "try:\n",
    "    model = SentenceTransformer(MODEL_PATH)\n",
    "    print(\"Loaded model from saved path.\")\n",
    "except:\n",
    "    model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "    model.save(MODEL_PATH)\n",
    "    print(\"Downloaded and saved model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f1ee3e8-4c66-4825-a25d-0848fa93c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text.lower())\n",
    "    processed_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(processed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dee94f9-7535-44a4-a2a0-4d66868edeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def rank_sentences(text, sentences):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    text_embedding = model.encode(text)\n",
    "    sentence_scores = {}\n",
    "    for sentence in sentences:\n",
    "        sentence_embedding = model.encode(sentence)\n",
    "        similarity = cosine_similarity([text_embedding], [sentence_embedding])[0][0]\n",
    "        sentence_scores[sentence] = similarity\n",
    "    ranked_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n",
    "    return ranked_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8c451be-4069-44d3-a8ff-5cb6301efbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmr(doc_embedding, sentence_embeddings, sentences, diversity=0.5):\n",
    "    selected_indices = []\n",
    "    remaining_indices = list(range(len(sentences)))\n",
    "    while len(selected_indices) < len(sentences):\n",
    "        best_score = -float('inf')\n",
    "        best_idx = None\n",
    "        for idx in remaining_indices:\n",
    "            similarity_to_doc = cosine_similarity([doc_embedding], [sentence_embeddings[idx]])[0][0]\n",
    "            if not selected_indices:\n",
    "                score = similarity_to_doc\n",
    "            else:\n",
    "                similarities_to_selected = cosine_similarity([sentence_embeddings[idx]], \n",
    "                                                            [sentence_embeddings[i] for i in selected_indices])\n",
    "                max_similarity = max(similarities_to_selected)[0]\n",
    "                score = diversity * similarity_to_doc - (1 - diversity) * max_similarity\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_idx = idx\n",
    "        selected_indices.append(best_idx)\n",
    "        remaining_indices.remove(best_idx)\n",
    "    return [sentences[i] for i in selected_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b19d2070-3074-4544-8ab7-cb13ddd78f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "def abstractive_summary(text, max_length=100):\n",
    "    \"\"\"\n",
    "    Generate an abstractive summary using BART.\n",
    "    \"\"\"\n",
    "    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=max_length,\n",
    "        min_length=30,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced17303-b432-4e1b-aaf8-e6bf0223731e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddfac396-cecd-46de-91c6-2ef62ed32018",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals. Colloquially, the term \"artificial intelligence\" is often used to describe machines that mimic cognitive functions that humans associate with the human mind, such as learning and problem-solving. As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI, a phenomenon known as the AI effect. A quip in Tesler's Theorem says \"AI is whatever hasn't been done yet.\" For instance, optical character recognition is frequently excluded from things considered to be AI, having become a routine technology.\n",
    "\"\"\"\n",
    "\n",
    "reference_summary = \"AI demonstrates intelligence by machines, contrasting human intelligence. It is defined as the study of intelligent agents that maximize their chances of achieving goals. The term is often used to describe machines mimicking cognitive functions like learning and problem-solving. As machines improve, tasks requiring intelligence are often redefined, known as the AI effect. Optical character recognition is an example of a technology that has become routine and is no longer considered AI.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85a18039-7079-4dbf-9989-43e459749c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Summary:\n",
      " Artificial intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals. Leading AI textbooks define the field as the study of \"intelligent agents\" As machines become increasingly capable, tasks considered to require \"intelligence\" are often removed from the definition of AI.\n"
     ]
    }
   ],
   "source": [
    "summary_length = 3\n",
    "summary = abstractive_summary(text)\n",
    "print(\"\\nGenerated Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c4977c5-6d28-4306-9d38-412739592a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores:\n",
      "rouge1: Precision=0.1633, Recall=1.0000, F-measure=0.2807\n",
      "rouge2: Precision=0.0208, Recall=0.1429, F-measure=0.0364\n",
      "rougeL: Precision=0.1429, Recall=0.8750, F-measure=0.2456\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def evaluate_summary(reference_summary, generated_summary):\n",
    "    \"\"\"\n",
    "    Evaluate the generated summary using ROUGE scores.\n",
    "    \"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(reference_summary, generated_summary)\n",
    "    return scores\n",
    "\n",
    "reference_summary = \"AI demonstrates intelligence by machines, contrasting human intelligence...\"\n",
    "generated_summary = summary\n",
    "\n",
    "scores = evaluate_summary(reference_summary, generated_summary)\n",
    "\n",
    "print(\"ROUGE Scores:\")\n",
    "for metric, score in scores.items():\n",
    "    print(f\"{metric}: Precision={score.precision:.4f}, Recall={score.recall:.4f}, F-measure={score.fmeasure:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a418f-9584-4dbc-8165-bd37e7f41252",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef235e-8416-403a-a659-e3f52daba84a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
